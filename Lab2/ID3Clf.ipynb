{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup ToyData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToyData:\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.attributes = {'color':['y', 'g', 'b'], 'size':['s','l'], 'shape':['r', 'i']}\n",
    "        self.classes = ('+', '-')\n",
    "\n",
    "        self.data = [('y', 's', 'r'),\n",
    "                 ('y', 's', 'r'),\n",
    "                 ('g', 's', 'i'),\n",
    "                 ('g', 'l', 'i'),\n",
    "                 ('y', 'l', 'r'),\n",
    "                 ('y', 's', 'r'),\n",
    "                 ('y', 's', 'r'),\n",
    "                 ('y', 's', 'r'),\n",
    "                 ('g', 's', 'r'),\n",
    "                 ('y', 'l', 'r'),\n",
    "                 ('y', 'l', 'r'),\n",
    "                 ('y', 'l', 'r'),\n",
    "                 ('y', 'l', 'r'),\n",
    "                 ('y', 'l', 'r'),\n",
    "                 ('y', 's', 'i'),\n",
    "                 ('y', 'l', 'i')]\n",
    "        self.target = ('+', '-', '+', '-', '+', '+', '+', '+', '-', '-', '+', '-', '-', '-', '+', '+')\n",
    "\n",
    "        self.testData = [('y', 's', 'r'),\n",
    "                 ('y', 's', 'r'),\n",
    "                 ('g', 's', 'i'),\n",
    "                 ('g', 'l', 'i'),\n",
    "                 ('y', 'l', 'r')]\n",
    "\n",
    "        self.testTarget = ('+', '-', '+', '-', '+')\n",
    "\n",
    "    def get_data(self):\n",
    "        return self.attributes, self.classes, self.data, self.target, self.testData, self.testTarget\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement decision tree classifier based on the ID3 algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from graphviz import Digraph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ID3DecisionTreeClassifier :\n",
    "    def __init__(self, minSamplesLeaf = 1, minSamplesSplit = 2) :\n",
    "\n",
    "        self.__nodeCounter = 0\n",
    "\n",
    "        # the graph to visualise the tree\n",
    "        self.__dot = Digraph(comment='The Decision Tree')\n",
    "\n",
    "        # suggested attributes of the classifier to handle training parameters\n",
    "        self.__minSamplesLeaf = minSamplesLeaf\n",
    "        self.__minSamplesSplit = minSamplesSplit\n",
    "\n",
    "\n",
    "    # Create a new node in the tree with the suggested attributes for the visualisation.\n",
    "    # It can later be added to the graph with the respective function\n",
    "    def new_ID3_node(self):\n",
    "        node = {'id': self.__nodeCounter, 'label': None, 'attribute': None, 'entropy': None, 'samples': None,\n",
    "                         'classCounts': None, 'nodes': None}\n",
    "\n",
    "        self.__nodeCounter += 1\n",
    "        return node\n",
    "\n",
    "    # adds the node into the graph for visualisation (creates a dot-node)\n",
    "    def add_node_to_graph(self, node, parentid=-1):\n",
    "        nodeString = ''\n",
    "        for k in node:\n",
    "            if ((node[k] != None) and (k != 'nodes')):\n",
    "                nodeString += \"\\n\" + str(k) + \": \" + str(node[k])\n",
    "\n",
    "        self.__dot.node(str(node['id']), label=nodeString)\n",
    "        if (parentid != -1):\n",
    "            self.__dot.edge(str(parentid), str(node['id']))\n",
    "\n",
    "    # make the visualisation available\n",
    "    def make_dot_data(self) :\n",
    "        return self.__dot\n",
    "\n",
    "    # For you to fill in; Suggested function to find the best attribute to split with, given the set of\n",
    "    # remaining attributes, the currently evaluated data and target.\n",
    "    def find_split_attr(self, data,target,attributes,classes):\n",
    "        max_info_gain = None\n",
    "        for attr in attributes:\n",
    "            remaining_attr = self.removekey(attributes,attr)\n",
    "            i_gain, ent = self.info_gain(attr, data,target,attributes,classes)\n",
    "            print(ent)\n",
    "            if max_info_gain is None or i_gain > max_info_gain:\n",
    "                max_info_gain = i_gain\n",
    "                max_info_gain_attr = attr\n",
    "                \n",
    "        return max_info_gain_attr, ent\n",
    "    \n",
    "    def removekey(self, d, key):\n",
    "        r = dict(d)\n",
    "        del r[key]\n",
    "        return r\n",
    "    \n",
    "    def entropy_split(self,data,col,val,counter):\n",
    "        \n",
    "        for i in range(len(data)):\n",
    "            if data[i][col] == val:\n",
    "                cnt[target[i]] += 1\n",
    "            \n",
    "        n_v = len(list(cnt.elements()))\n",
    "        ent_v = 0\n",
    "        for cl in classes:\n",
    "            p_x = cnt[cl]/n_v\n",
    "            ent_v += -p_x*math.log(p_x,2)\n",
    "        return ent_v, n_v\n",
    "    \n",
    "    def info_gain(self,split, data,target,attributes,classes):\n",
    "        # Calculate the entropy first\n",
    "        entropy = 0\n",
    "        cnt = Counter(target)\n",
    "        n = len(target)\n",
    "        \n",
    "        for cl in classes:\n",
    "            p_x = cnt[cl]/n\n",
    "            entropy += - p_x * math.log(p_x)\n",
    "        \n",
    "        col = list(attributes.keys()).index(split)\n",
    "        info_gain = entropy\n",
    "        for val in attributes[split]:\n",
    "            cnt = Counter()\n",
    "            ent_v, n_v = self.entropy_split(data, col, val, cnt)\n",
    "            info_gain += - n_v/n*ent_v\n",
    "            \n",
    "        return info_gain, entropy\n",
    "            \n",
    "                \n",
    "    # Use this function split the data acording to the split attribute\n",
    "    # Return values are dicts with value of split attribute as keys and the data/targets as items.\n",
    "    def find_data_split(self,data,target,attributes,classes,split):\n",
    "        data_split = {}\n",
    "        target_split = {}\n",
    "        if len(attributes) > 1:\n",
    "            col = list(attributes.keys()).index(split)\n",
    "        else:\n",
    "            col = 0\n",
    "        for vals in attributes[split]:\n",
    "            data_split[vals] = []\n",
    "            target_split[vals] = []\n",
    "            for i in range(len(target)):\n",
    "                if data[i][col] == vals:\n",
    "                    data_split[vals].append(data[i])\n",
    "                    target_split[vals].append(target[i])\n",
    "                   \n",
    "                    \n",
    "        return data_split, target_split\n",
    "        \n",
    "\n",
    "    # the entry point for the recursive ID3-algorithm, you need to fill in the calls to your recursive implementation\n",
    "    def fit(self, data, target, attributes, classes):\n",
    "        node = self.new_ID3_node()\n",
    "        self.add_node_to_graph(node)\n",
    "        cnt = Counter(target)\n",
    "        node['samples'] = len(target)\n",
    "        node['classCounts'] = cnt\n",
    "        if len(cnt) == 1:\n",
    "            node['label'] = target[0]\n",
    "            return node\n",
    "        \n",
    "        elif len(attributes) == 0:\n",
    "            node['label'] = cnt.most_common(1)[0][0]\n",
    "            return node\n",
    "        else:\n",
    "            split,ent = self.find_split_attr(data,target,attributes,classes)\n",
    "            node['nodes'] = {}\n",
    "            node['entropy'] = ent\n",
    "            node['attribute'] = split\n",
    "            remaining_attr = self.removekey(attributes, split)\n",
    "            fit_data, fit_target = self.find_data_split(data,target,attributes,classes,split)    \n",
    "            \n",
    "            for vals in attributes[split]:\n",
    "                if len(fit_target[vals]) == 0:\n",
    "                    leaf_node = self.new_ID3_node()\n",
    "                    leaf_node['label'] = cnt.most_common(1)[0][0]\n",
    "                    node['nodes'][vals] = leaf_node\n",
    "                else:\n",
    "                    node['nodes'][vals] = self.fit(fit_data[vals],fit_target[vals],remaining_attr,classes)\n",
    "\n",
    "        # fill in something more sensible here..  root should become the output of the recursive tree creation\n",
    "        # root = self.new_ID3_node()\n",
    "        # self.add_node_to_graph(root)\n",
    "\n",
    "        return node\n",
    "    \n",
    "\n",
    "    def predict(self, data, tree) :\n",
    "        predicted = list()\n",
    "\n",
    "        # fill in something more sensible here... root should become the output of the recursive tree creation\n",
    "        return predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the ID3 classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import ToyData as td\n",
    "#import ID3\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn import tree, metrics, datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6853142072764582\n",
      "0.6853142072764582\n",
      "0.6853142072764582\n",
      "0.5623351446188083\n",
      "0.5623351446188083\n",
      "0.6615632381579821\n",
      "0.6615632381579821\n",
      "{'id': 0, 'label': None, 'attribute': 'size', 'entropy': 0.6853142072764582, 'samples': 16, 'classCounts': Counter({'+': 9, '-': 7}), 'nodes': {'s': {'id': 1, 'label': None, 'attribute': 'shape', 'entropy': 0.5623351446188083, 'samples': 8, 'classCounts': Counter({'+': 6, '-': 2}), 'nodes': {'r': {'id': 2, 'label': '+', 'attribute': None, 'entropy': None, 'samples': None, 'classCounts': None, 'nodes': None}, 'i': {'id': 3, 'label': '+', 'attribute': None, 'entropy': None, 'samples': None, 'classCounts': None, 'nodes': None}}}, 'l': {'id': 4, 'label': None, 'attribute': 'shape', 'entropy': 0.6615632381579821, 'samples': 8, 'classCounts': Counter({'-': 5, '+': 3}), 'nodes': {'r': {'id': 5, 'label': '-', 'attribute': None, 'entropy': None, 'samples': None, 'classCounts': None, 'nodes': None}, 'i': {'id': 6, 'label': '-', 'attribute': None, 'entropy': None, 'samples': None, 'classCounts': None, 'nodes': None}}}}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'testTree.pdf'"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributes, classes, data, target, data2, target2 = ToyData().get_data()\n",
    "\n",
    "id3 = ID3DecisionTreeClassifier()\n",
    "\n",
    "myTree = id3.fit(data, target, attributes, classes)\n",
    "print(myTree)\n",
    "plot = id3.make_dot_data()\n",
    "plot.render(\"testTree\")\n",
    "# predicted = id3.predict(data2, myTree)\n",
    "# print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes\n",
    "split = 'color'\n",
    "col = list(attributes.keys()).index(split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-111-aecde4c53d05>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mval\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mattributes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mcnt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0ment_v\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_v\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mentropy_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcnt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[0minfo_gain\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mn_v\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ment_v\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-111-aecde4c53d05>\u001b[0m in \u001b[0;36mentropy_split\u001b[1;34m(data, col, val, counter)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcl\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mp_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcnt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcl\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mn_v\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0ment_v\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mp_x\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0ment_v\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_v\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "split = 'color'\n",
    "col = list(attributes.keys()).index(split)\n",
    "\n",
    "def entropy_split(data,col,val,counter):\n",
    "    n_v = 0\n",
    "    ent_v = 0\n",
    "    for i in range(len(data)):\n",
    "        if data[i][col] == val:\n",
    "            cnt[target[i]] += 1\n",
    "            n_v += 1\n",
    "        \n",
    "    for cl in classes:\n",
    "        p_x = cnt[cl]/n_v\n",
    "        ent_v += -p_x*math.log(p_x,2)\n",
    "    return ent_v, n_v\n",
    "\n",
    "n = len(data)\n",
    "entropy = 0\n",
    "info_gain = entropy\n",
    "for val in attributes[split]:\n",
    "    cnt = Counter()\n",
    "    ent_v, n_v = entropy_split(data, col, val, cnt)\n",
    "    info_gain += - n_v/n*ent_v\n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes, classes, data, target, data2, target2 = ToyData().get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'+'"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = Counter(target)\n",
    "cnt.most_common(1)[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'+'"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
